{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO27ViqvEGRUNmgFUpkaTo/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinsusong/Predict-CVE-CWE/blob/main/CVE_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCfFC6KcomhI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Meta/meta-learning-bert\""
      ],
      "metadata": {
        "id": "6NWzuYViotwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pwd\n",
        "%ls -al"
      ],
      "metadata": {
        "id": "ot49ketrrVRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!git clone https://github.com/mailong25/meta-learning-bert.git"
      ],
      "metadata": {
        "id": "lEaxneSypFGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Set 확인 "
      ],
      "metadata": {
        "id": "-nCW6CbSx-HS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## How to build an accurate sentiment analysis model with handful training examples\n",
        "\n",
        "# 취약점 설명을 유형에 따라 150가지 범주로 범주로 분류하는 모델을 교육하려고 한다.\n",
        "# 각 취약점 및 유형에 대해 단일 모델을 사용한다.\n",
        "# 일부 취약점에서는 제한된 수의 학습 예제만 가지고 있다. low-resource domain \n",
        "\n",
        "# Let inspect the data\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_excel(\"/content/drive/MyDrive/Meta/SD_Vulnerability_Dataset.xlsx\")\n",
        "data = data[['index','CVE-ID','DESCRIPTION', 'CWE-ID','CWE-NAME']]\n",
        "# 데이터 개수 확인  len : 21855\n",
        "print(len(data))\n",
        "# 데이터 확인 \n",
        "data\n",
        "\n",
        "# 데이터 형태 확인\n",
        "\"\"\"\n",
        "index\t        : 1\n",
        "CVE-ID\t        : CVE-1999-0199\n",
        "DESCRIPTION\t    : manual/search.texi in the GNU C Library (aka g...\t\n",
        "CWE-ID\t        : CWE-252\n",
        "CWE-NAME        : Unchecked Return Value\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Q5zHm_jJpHA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 해결 방안\n",
        "# 많은 학습 데이터를 가진 도메인을 활용하여 좋은 starting point를 만들고 이 시점부터 적은 데이터를 가진 특정 모델에 대한 학습한다. \n",
        "\n",
        "# 접근법\n",
        "# Meta learning : 적은 학습 데이터만으로 빠르게 학습해야하는 많은 상황을 시뮬레이션한다., 많은 상황을 반복할수록 적은 학습 데이터로 학습하는데 더 좋아지고 있다. \n",
        "# Support set : 적은 훈련 샘플\n",
        "# Query set :  학습 피드백을 제공. 모델은 이 피드백을 사용하여 학습 전략을 조정한다. \n"
      ],
      "metadata": {
        "id": "nz0uWUEdrQbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create  Mata learning Task (task.py)"
      ],
      "metadata": {
        "id": "YMWZCYIKx3Xo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GSTpud2KNIBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import torch \n",
        "from torch.utils.data import Dataset \n",
        "import numpy as np \n",
        "import collections \n",
        "import random \n",
        "import json, pickle \n",
        "from torch.utils.data import TensorDataset # DataLoader : 배치를 쉽게 사용, TensorDataset : X, Y 를 텐서로 묶기 위해 사용\n",
        "\n",
        "LABEL_MAP = {'positive' :0 , 'negative' :1, 0:'positive', 1:'negative'}\n",
        "\n",
        "class MetaTask(Dataset):\n",
        "    def __init__(self, examples, num_task, k_support, k_query, tokenizer):\n",
        "        \"\"\"\n",
        "        : param sample: list of samples\n",
        "        : param num-task: number of training tasks.\n",
        "        : param k_support : number of support sample per task\n",
        "        : param k_query : number of query sample per task \n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\" eamples[0]\n",
        "        index                                                          2\n",
        "        CVE-ID                                             CVE-1999-0284\n",
        "        DESCRIPTION    Denial of service to NT mail servers including...\n",
        "        CWE-ID                                                   CWE-120\n",
        "        CWE-NAME       Buffer Copy without Checking Size of Input ('C...\n",
        "        \"\"\"\n",
        "\n",
        "        self.examples = examples\n",
        "        random.shuffle(self.examples)\n",
        "\n",
        "        self.num_task = num_task\n",
        "        self.k_support = k_support\n",
        "        self.k_query = k_query\n",
        "        self.tokenizer = tokenizer \n",
        "        self.max_seq_length = 512 #128\n",
        "        self.create_batch(self.num_task)\n",
        "\n",
        "    def create_batch(self, num_task):\n",
        "        self.supports = [] # support set \n",
        "        self.queries = [] # query set\n",
        "\n",
        "        for b in range(num_task): # for each task \n",
        "        #for b in range(1): # for each task \n",
        "            # 1. select domain randomly\n",
        "            # 각 태스크에 들어갈 5개의 유형을 선택 \n",
        "            # 5개의 유형에 대한 데이터를 모두 모으기 \n",
        "            \n",
        "            domain = random.choice(self.examples)['CWE-ID'] # 'CWE-ID': 'CWE-94'\n",
        "            #domain = 'CWE-78'\n",
        "            #domain = 'CWE-78'\n",
        "            domainExamples = [e for e in self.examples if e['CWE-ID'] == domain] # domainExamples에는 어떤 형태의 데이터가 들어가는가? \n",
        "            \n",
        "            #print(\"domain :\" , domain)\n",
        "            #print(\"len(domainExamples) : \" , len(domainExamples))\n",
        "            \n",
        "            # 1. select k_support + k_query examples from domain randomly \n",
        "            #  random.sample() : 지정한 숫자만큼의 요소들을 랜덤으로 뽑아 리스트로 반환\n",
        "            # 취약점 개수가 100개 이하면 support , query 의 개수를 더했을 때 갯수가 안맞아서 if 사용\n",
        "            if len(domainExamples) <= 130:\n",
        "                selected_examples = random.sample(domainExamples, len(domainExamples)) \n",
        "                random.shuffle(selected_examples)\n",
        "                exam_train = selected_examples[:self.k_support]\n",
        "                exam_test = selected_examples[self.k_support:]    \n",
        "            else:\n",
        "                selected_examples = random.sample(domainExamples, self.k_support + self.k_query)            \n",
        "                random.shuffle(selected_examples)\n",
        "                exam_train = selected_examples[:self.k_support]\n",
        "                exam_test = selected_examples[self.k_support:]\n",
        "            #print(\"len exam_train : \" , len(exam_train))\n",
        "            #print(\"len exam_test : \" , len(exam_test))\n",
        "\n",
        "            self.supports.append(exam_train)\n",
        "            self.queries.append(exam_test)\n",
        "\n",
        "    def create_feature_set(self, examples):\n",
        "        print(\"create_feature_set start\")\n",
        "        # torch.empty(num1,num2)는 (num1 x num2) 크기의 행렬을 구성하면서 초기화되지 않은 데이터로 값을 채움\n",
        "        all_input_ids       = torch.empty(len(examples), self.max_seq_length, dtype = torch.long)\n",
        "        all_attention_mask   = torch.empty(len(examples), self.max_seq_length, dtype = torch.long)\n",
        "        all_segment_ids     = torch.empty(len(examples), self.max_seq_length, dtype = torch.long)\n",
        "        all_label_ids       = torch.empty(len(examples), dtype = torch.long)\n",
        "\n",
        "        \n",
        "        \n",
        "        # 변수 뒤에 _ 를 사용하는 이유는 파이썬 기본 시스템 변수명과 충돌을 피하기 위해서이다.\n",
        "        print(\"!\")\n",
        "        for id_, example in enumerate(examples):\n",
        "            input_ids       = tokenizer.encode(example['DESCRIPTION'], truncation=True, max_length=512) # tokenizer.encode(example['text'])\n",
        "            #print(\"input_ids : \" , input_ids)\n",
        "            #print(\"input_ids len : \" , len(input_ids))\n",
        "            #print(\"input_ids shape : \" , np.shape(input_ids))\n",
        "            attention_mask  = [1] * len(input_ids)\n",
        "            segment_ids     = [0] * len(input_ids)\n",
        "\n",
        "            # 패딩\n",
        "            while len(input_ids) < self.max_seq_length: \n",
        "                input_ids.append(0)\n",
        "                attention_mask.append(0)\n",
        "                segment_ids.append(0)\n",
        "\n",
        "            # 영문으로 이루어진 label을 숫자로 표현\n",
        "            # 'label': 'positive' , LABEL_MAP = 'positive' :0 \n",
        "            #label_id = LABEL_MAP[example['label']] \n",
        "\n",
        "            label_id = label_dict[example['CWE-ID']]\n",
        "            print(\"example['CWE-ID'] : \", example['CWE-ID'])\n",
        "            print(\"label_id : \" , label_id)\n",
        "            all_input_ids[id_] = torch.Tensor(input_ids).to(torch.long)\n",
        "            all_attention_mask[id_] = torch.Tensor(attention_mask).to(torch.long)\n",
        "            all_segment_ids[id_] = torch.Tensor(segment_ids).to(torch.long)\n",
        "            all_label_ids[id_] = torch.Tensor([label_id]).to(torch.long)\n",
        "\n",
        "        print(\"!!\")\n",
        "        tensor_set = TensorDataset(all_input_ids, all_attention_mask, all_segment_ids, all_label_ids)\n",
        "        return tensor_set\n",
        "\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        print(\"__getitem__ start\")\n",
        "        print(\"index : \" , index)\n",
        "        print(\"len supports : \" , len(self.supports))\n",
        "        support_set = self.create_feature_set(self.supports[index])\n",
        "        print(\"**\")\n",
        "        query_set = self.create_feature_set(self.queries[index])\n",
        "        print(\"***\")\n",
        "        return support_set, query_set \n",
        "\n",
        "    def __len__(self):\n",
        "        # 데이터 세트를 한 묶음으로 만들었기 때문에 집합의 작은 배치 크기를 샘플로 추출할 수 있습니다.\n",
        "        return self.num_task\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "y9YzWGb1x8rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Split meta training and meta testing"
      ],
      "metadata": {
        "id": "dLjHU7ddBlkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CWE-ID 유일한 값별로 개수 세기 \n",
        "data_counts=data['CWE-ID'].value_counts()\n",
        "#print(data_counts)\n",
        "#print(i , \":\", data_counts.index[i]) # 유형 ID \n",
        "#print(i , \":\", data_counts.values[i]) # 유형 별 취약점 개수\n",
        "\n",
        "# 유형 ID\n",
        "id_of_vulnerability = data_counts.index.to_list()\n",
        "# 유형 별 취약점 개수 \n",
        "number_of_vulnerability = data_counts.values.tolist()\n",
        "\n",
        "\n",
        "# 취약점이 100개 이상인 유형 골라내기 \n",
        "high_resource_domains = []\n",
        "\n",
        "# 유형 만큼 반복 돌면서 train 데이터와 test 데이터 분리  \n",
        "for i in range(len(data_counts)):\n",
        "    # 취약점 개수가 100보다 큰 경우 train_example로 추가 , \n",
        "    # 취약점 개수가 100보다 작은 경우 test_example로 추가\n",
        "    if number_of_vulnerability[i] > 100: \n",
        "        high_resource_domains.append(id_of_vulnerability[i])\n",
        "\n",
        "\n",
        "print(len(high_resource_domains))\n",
        "print(high_resource_domains)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K41DntFGrTiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# 레이블 인코딩\n",
        "label_dict = {}\n",
        "for index, cwe_label in enumerate(id_of_vulnerability):\n",
        "    #print(\"index: \" ,index)\n",
        "    #print(cwe_label)\n",
        "    label_dict[cwe_label] = index\n",
        "label_dict"
      ],
      "metadata": {
        "id": "Z85FFELXNwqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 데이터 개수에 따른 유형 분류\n",
        "train_examples = [] # 학습 데이터 개수가 많은 유형 100 < \n",
        "test_examples = [] # 학습 데이터 개수가 적은 유형  100 > \n",
        "print(type(data))\n",
        "for index , row in data.iterrows():\n",
        "    #print(\"\\n\\nr : \", row)\n",
        "    if row['CWE-ID'] in high_resource_domains:\n",
        "        #print(\"true\")\n",
        "        train_examples.append(row)\n",
        "    else:\n",
        "        #print(\"false\")\n",
        "        test_examples.append(row)\n",
        "\n",
        "\n",
        "print(len(train_examples), len(test_examples))"
      ],
      "metadata": {
        "id": "3rUHtG615j6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_examples[0])\n",
        "train_examples[0]['CVE-ID'] # list"
      ],
      "metadata": {
        "id": "OO8-c-PtGab-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "f8-TZPQm6iU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "from transformers import BertModel, BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\n",
        "train = MetaTask(train_examples, num_task = 100, k_support=100, k_query=30, tokenizer = tokenizer)"
      ],
      "metadata": {
        "id": "31sZvsvt5-TD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 메타 태스크의 support set 처음 샘플 확인해보기\n",
        "#print(train.supports[0])\n",
        "#print(train.supports[0][:2])\n",
        "print(\"\\n\")\n",
        "print(train.queries[0][1:2])"
      ],
      "metadata": {
        "id": "yMPNhBnT6cFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫번째 메타 태스크의 정보이다. support set과 query set을 포함하는 텐서 데이터세트\n",
        "train[0]\n",
        "#len(train)"
      ],
      "metadata": {
        "id": "HbqUebJH77oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플을 확인하기 \n",
        "train[0][0][:2]\n"
      ],
      "metadata": {
        "id": "epKi2Q2X8mjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training meta (main.py)"
      ],
      "metadata": {
        "id": "XfjJgO9_8tkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time \n",
        "import logging \n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.CRITICAL)\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "def random_seed(value):\n",
        "    # 실험 재현성을 위해서 제어해야할 randomness\n",
        "    # PyTorch 작업이 \"결정적\" 알고리즘을 사용해야 하는지 여부를 설정합니다. 즉, 동일한 입력이 주어지고 동일한 소프트웨어 및 하드웨어에서 실행될 때 항상 동일한 출력을 생성하는 알고리즘\n",
        "    torch.backends.cudnn.daterministic=True \n",
        "    torch.manual_seed(value)\n",
        "    torch.cuda.manual_seed(value)\n",
        "    np.random.seed(value)\n",
        "    random.seed(value)\n",
        "\n",
        "def create_batch_of_tasks(taskset, is_shuffle = True, batch_size = 4):\n",
        "    # task 수 만큼 번호 리스트를 만든다.\n",
        "    print(\" create_batch_of_tasks start\")\n",
        "    idxs = list(range(0,len(taskset)))\n",
        "    if is_shuffle:\n",
        "        random.shuffle(idxs)\n",
        "    print(\"end\")\n",
        "    for i in range(0,len(idxs), batch_size):\n",
        "        yield [taskset[idxs[i]] for i in range(i, min(i + batch_size, len(taskset)))] #  yield 여러 개의 데이터를 미리 만들어 놓지 않고 필요할 때마다 즉석해서 하나씩 만들어낼 수 있는 객체를 의미\n",
        "\n",
        "class TrainingArgs:\n",
        "    def __init__(self):\n",
        "        self.num_labels = 2\n",
        "        self.meta_epoch=10\n",
        "        self.k_spt=80\n",
        "        self.k_qry=20\n",
        "        self.outer_batch_size = 2\n",
        "        self.inner_batch_size = 12\n",
        "        self.outer_update_lr = 5e-5\n",
        "        self.inner_update_lr = 5e-5\n",
        "        self.inner_update_step = 10\n",
        "        self.inner_update_step_eval = 40\n",
        "        self.bert_model = 'bert-base-uncased'\n",
        "        self.num_task_train = 500\n",
        "        self.num_task_test = 5\n",
        "\n",
        "args = TrainingArgs()\n"
      ],
      "metadata": {
        "id": "O2XE01pv8-uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create meta Learner (Reptile.py) "
      ],
      "metadata": {
        "id": "z3kN-tAfU918"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F \n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler \n",
        "from torch.optim import Adam \n",
        "from torch.nn import CrossEntropyLoss\n",
        "from transformers import BertForSequenceClassification \n",
        "from copy import deepcopy \n",
        "import gc \n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch \n",
        "import numpy as np\n",
        "\n",
        "class Learner(nn.Module):\n",
        "    \"\"\"\n",
        "    Meta Learner \n",
        "    \"\"\"\n",
        "    def __init__(self, args):\n",
        "        \"\"\"\n",
        "        param args:\n",
        "        \"\"\"\n",
        "        super(Learner, self).__init__()\n",
        "        \n",
        "        self.num_labels = args.num_labels\n",
        "        self.outer_batch_size = args.outer_batch_size\n",
        "        self.inner_batch_size = args.inner_batch_size\n",
        "        self.outer_update_lr  = args.outer_update_lr\n",
        "        self.inner_update_lr  = args.inner_update_lr\n",
        "        self.inner_update_step = args.inner_update_step\n",
        "        self.inner_update_step_eval = args.inner_update_step_eval\n",
        "        self.bert_model = args.bert_model\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        \n",
        "        self.model = BertForSequenceClassification.from_pretrained(self.bert_model, num_labels = self.num_labels)\n",
        "        self.outer_optimizer = Adam(self.model.parameters(), lr=self.outer_update_lr)\n",
        "        self.model.train() #  모델을 학습 모드로 변환\n",
        "\n",
        "    def forward(self, batch_tasks, training = True):\n",
        "        \"\"\"\n",
        "        batch = [\n",
        "            (support TensorDataset, query TensorDataset),\n",
        "            (support TensorDataset, query TensorDataset),\n",
        "            (support TensorDataset, query TensorDataset),\n",
        "            (support TensorDataset, query TensorDataset),\n",
        "        ]\n",
        "        # support = TensorDataset( all_input_ids, all_attentnion_mask, all_segment_ids, all_label_ids)\n",
        "        \"\"\"\n",
        "        print(\"forward start \")\n",
        "        task_accs = []\n",
        "        sum_gradients = []\n",
        "        num_task = len(batch_tasks)\n",
        "        # 왜 batch_tasks = 2인 이유 (support 랑 query라서  2)\n",
        "        \n",
        "        num_inner_update_step = self.inner_update_step if training else self.inner_update_step_eval\n",
        "        # inner_update_step : 내부 루프의 반복 횟수\n",
        "\n",
        "        for task_id, task in enumerate(batch_tasks):\n",
        "            print(\"task_id : \", task_id)\n",
        "            support = task[0]\n",
        "            print(\"len support set : \" , len(support))\n",
        "            query = task[1]\n",
        "            print(\"len query set : \" , len(query))\n",
        "\n",
        "            # fast_model은 Outer bert를 복제함. 아마도 inner model 인듯? \n",
        "            fast_model = deepcopy(self.model)\n",
        "            #fast_model.config.max_position_embeddings = 1024\n",
        "            fast_model.to(self.device)\n",
        "            # sampler : Dataset을 인자로 받아 data의 index를 반환, shuffle을 하기 위해 사용\n",
        "            support_dataloader = DataLoader(support, sampler=RandomSampler(support),\n",
        "                                            batch_size = self.inner_batch_size)\n",
        "            \n",
        "            inner_optimizer = Adam(fast_model.parameters(), lr=self.inner_update_lr)\n",
        "            fast_model.train()\n",
        "\n",
        "            # innder model loss ?????\n",
        "            print('----Task', task_id, '---')\n",
        "            print(\"num_inner_update_step : \" , num_inner_update_step)\n",
        "            for i in range(0, num_inner_update_step):\n",
        "                print(\" i : \", i)\n",
        "                all_loss = [] \n",
        "                for inner_step, batch in enumerate(support_dataloader):\n",
        "                    print(\"inner_step start \")\n",
        "                    batch = tuple(t.to(self.device) for t in batch)\n",
        "                    input_ids, attention_mask, segment_ids, label_id = batch\n",
        "                    #print(\"input_ids : \" , input_ids)\n",
        "                    outputs = fast_model(input_ids, attention_mask, segment_ids, labels = label_id)\n",
        "                    #print(\"outputs : \" , outputs)\n",
        "                    loss = outputs[0]\n",
        "                    print(\"loss : \", loss)\n",
        "                    loss.backward()\n",
        "                    print(\"loss.backward() 실행\")\n",
        "                    inner_optimizer.step()\n",
        "                    print(\"inner_optimizer.step()\", inner_optimizer.step())\n",
        "                    inner_optimizer.zero_grad()\n",
        "                    print(\"inner_optimizer.zero_grad 실행\")\n",
        "                    all_loss.append(loss.item())\n",
        "                    print(\"all_loss : \" , all_loss)\n",
        "                    \n",
        "                if i % 4 == 0:\n",
        "                    print(\"Inner Loss : \", np.mean(all_loss)) # mean : 배열의 평균 \n",
        "\n",
        "            fast_model.to(torch.device('cpu'))\n",
        "            \n",
        "            print(\"training start \")\n",
        "            # outer model과 inner model의 가중치를 비교하여 sum_gradient를 구함 \n",
        "            if training:\n",
        "                #print(\"meta_wights update , len(weights) : \", len(meta_weights))\n",
        "                meta_weights = list(self.model.parameters()) # outer model \n",
        "                fast_weights = list(fast_model.parameters()) # inner model\n",
        "\n",
        "                gradients = []\n",
        "                for i, (meta_params, fast_params) in enumerate(zip(meta_weights, fast_weights)):\n",
        "                    gradient = meta_params - fast_params \n",
        "                    if task_id == 0:\n",
        "                        sum_gradients.append(gradient)\n",
        "                    else:\n",
        "                        sum_gradients[i] += gradient \n",
        "\n",
        "            # query data를 사용해 fast_model 평가 \n",
        "            fast_model.to(self.device)\n",
        "            fast_model.eval() # 학습을 위해 사용하는 Droupout, batchnorm 등을 비활성화 \n",
        "            with torch.no_grad(): # gradient를 계산해주는 context를 비활성화 \n",
        "                query_dataloader = DataLoader(query, sampler=None, batch_size=len(query))\n",
        "                query_batch = iter(query_dataloader).next()\n",
        "                query_batch = tuple(t.to(self.device) for t in query_batch)\n",
        "                q_input_ids, q_attention_mask, q_segment_ids, q_label_id = query_batch \n",
        "                q_outputs = fast_model(q_input_ids, q_attention_mask, q_segment_ids, labels = q_label_id)\n",
        "\n",
        "                q_logits = F.softmax(q_outputs[1], dim=1)\n",
        "                pre_label_id = torch.argmax(q_logits, dim=1)\n",
        "                pre_label_id = pre_label_id.detach().cpu().numpy().tolist()\n",
        "                q_label_id = q_label_id.detach().cpu().numpy().tolist()\n",
        "\n",
        "                acc = accuracy_score(pre_label_id, q_label_id)\n",
        "                task_accs.append(acc)\n",
        "\n",
        "            fast_model.to(torch.device('cpu'))\n",
        "            del fast_model, inner_optimizer\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        if training:\n",
        "            # Average gradient across tasks, 태스크 간 평균 기울기 \n",
        "            for i in range(0, len(sum_gradients)):\n",
        "                sum_gradients[i] = sum_gradients[i] / float(num_task)\n",
        "            \n",
        "            # 원래 모델에 그라디언트를 할당한 다음 옵티마이저를 사용하여 가중치를 업데이트 함.\n",
        "            for i, params in enumerate(self.model.parameters()):\n",
        "                params.grad = sum_gradients[i]\n",
        "\n",
        "            self.outer_optimizer.step()\n",
        "            self.outer_optimizer.zero_grad()\n",
        "\n",
        "            del sum_gradients\n",
        "            gc.collect()\n",
        "\n",
        "        print(\"forward start \")\n",
        "        return np.mean(task_accs)"
      ],
      "metadata": {
        "id": "Tu49TDrcU9k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner = Learner(args)"
      ],
      "metadata": {
        "id": "jlWqBeljiWfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_seed(123)\n",
        "# low-resource domain example을 태스크 별 support셋과 query 셋으로 분류 ? \n",
        "test = MetaTask(test_examples, num_task = 3, k_support=80, k_query=20, tokenizer = tokenizer)\n",
        "random_seed(int(time.time() % 10))"
      ],
      "metadata": {
        "id": "GnwfP4EYiaJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test.supports[2]"
      ],
      "metadata": {
        "id": "GHrCpRFQip72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Start training"
      ],
      "metadata": {
        "id": "kmlutewTglg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "global_step = 0 \n",
        "\n",
        "for epoch in range(args.meta_epoch):\n",
        "    print(\"epoch : \" , epoch)\n",
        "    #train = MetaTask(train_examples, num_task = 500, k_support=80, k_query=20, tokenizer = tokenizer)\n",
        "    train = MetaTask(train_examples, num_task = 100, k_support=80, k_query=20, tokenizer = tokenizer)\n",
        "    print(\"len train : \" ,len(train))\n",
        "    db = create_batch_of_tasks(train, is_shuffle = True, batch_size= args.outer_batch_size)\n",
        "    \n",
        "    for step, task_batch in enumerate(db):\n",
        "        \n",
        "        #print(\"task_batch len : \",len(task_batch))\n",
        "        #print(\"for step : \", step)\n",
        "        f = open('log.txt','a')\n",
        "\n",
        "        acc = learner(task_batch)\n",
        "        print(\"acc : \" , acc)\n",
        "\n",
        "        print('Step:', step, '\\ttraining Acc : ', acc)\n",
        "        f.write(str(acc) + '\\n')\n",
        "\n",
        "        if global_step % 20 == 0:\n",
        "            random_seed(123)\n",
        "            print(\"\\n--------------------Testing Mode ------------------\\n\")\n",
        "            db_test = create_batch_of_tasks(test, is_shuffle = False, batch_size = 1)\n",
        "            acc_all_test = []\n",
        "\n",
        "            for test_batch in db_test:\n",
        "                acc = learner(test_batch, training = False)\n",
        "                acc_all_test.append(acc)\n",
        "\n",
        "            print('Step : ', step, 'Test F1 : ', np.mean(acc_all_test))\n",
        "            f.write('Test ' + str(np.mean(acc_all_test)) + '\\n')\n",
        "\n",
        "            random_seed(int(time.time() % 10))\n",
        "\n",
        "        global_step += 1\n",
        "        f.close()\n",
        "\n"
      ],
      "metadata": {
        "id": "2_knYcWthC78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bTwmMzqriNpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7CLniCz8XLuQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}